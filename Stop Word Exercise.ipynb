{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b17f58fa",
   "metadata": {
    "id": "b17f58fa"
   },
   "source": [
    "###                     **Stop Words: Exercise**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a26def",
   "metadata": {
    "id": "23a26def"
   },
   "source": [
    "- **Run this cell to import all necessary packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34f02550",
   "metadata": {
    "id": "34f02550"
   },
   "outputs": [],
   "source": [
    "#import spacy and load the model\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe230d8",
   "metadata": {
    "id": "0fe230d8"
   },
   "source": [
    "**Exercise1:** \n",
    "- From a Given Text, Count the number of stop words in it.\n",
    "- Print the percentage of stop word tokens compared to all tokens in a given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "646c9e7a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "646c9e7a",
    "outputId": "7d59339e-bf53-4239-eda5-134e6af42e22"
   },
   "outputs": [],
   "source": [
    "text = '''\n",
    "Thor: not Love and Thunder is a 2022 American superhero film based on Marvel Comics featuring the character Thor, produced by Marvel Studios and \n",
    "distributed by Walt Disney Studios Motion Pictures. It is the sequel to Thor: Ragnarok (2017) and the 29th film in the Marvel Cinematic Universe (MCU).\n",
    "The film is directed by Taika Waititi, who co-wrote the script with Jennifer Kaytin Robinson, and stars Chris Hemsworth as Thor alongside Christian Bale, Tessa Thompson,\n",
    "Jaimie Alexander, Waititi, Russell Crowe, and Natalie Portman. In the film, Thor attempts to find inner peace, but must return to action and recruit Valkyrie (Thompson),\n",
    "Korg (Waititi), and Jane Foster (Portman)—who is now the Mighty Thor—to stop Gorr the God Butcher (Bale) from eliminating all gods.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94cf789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step1: Create the object 'doc' for the given text using nlp()\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22d5eaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161\n"
     ]
    }
   ],
   "source": [
    "#step2: define the variables to keep track of stopwords count and total words count\n",
    "token_count = len(doc)\n",
    "print(token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b29436f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Thor\n",
      ":\n",
      "not\n",
      "Love\n"
     ]
    }
   ],
   "source": [
    "#step3: iterate through all the words in the document\n",
    "for i, token in enumerate(doc):\n",
    "    if i >= 5:\n",
    "        break\n",
    "    print(token.text[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "216d5734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "#step4: print the count of stop words\n",
    "stop_token = []\n",
    "for token in doc:\n",
    "    if token.is_stop:\n",
    "        stop_token.append(token)\n",
    "stop_token_len = len(stop_token)\n",
    "print(stop_token_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "822b5d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[not, and, is, a, on, the, by, and, by, It, is, the, to, and, the, in, the, The, is, by, who, the, with, and, as, and, In, the, to, but, must, to, and, and, is, now, the, to, the, from, all]\n"
     ]
    }
   ],
   "source": [
    "print(stop_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vsJaC5a-ldY-",
   "metadata": {
    "id": "vsJaC5a-ldY-"
   },
   "source": [
    "**Exercise2:** \n",
    "\n",
    "- Spacy default implementation considers **\"not\"** as a stop word. But in some scenarios removing 'not' will completely change the meaning of the statement/text. For Example, consider these two statements:\n",
    "\n",
    "      - this is a good movie       ----> Positive Statement\n",
    "      - this is not a good movie   ----> Negative Statement\n",
    "\n",
    "- So, after applying stopwords to those 2 texts, both will return **\"good movie\"** and does not respect the polarity/sentiments of text.\n",
    "  \n",
    "- Now, your task is to remove this stop word **\"not\"** in spaCy and help in distinguishing the texts.\n",
    "\n",
    "\n",
    "- **Hint:** GOOGLE IT! Google is your friend.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3f5f578",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1=''' This is a good movie.This is not a good movie '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba50468e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step1: remove the stopword 'not' in spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e9e663a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4e9e663a",
    "outputId": "72779ead-6cb9-4f92-da54-3e3a882c2069"
   },
   "outputs": [],
   "source": [
    "#use this pre-processing function to pass the text and to remove all the stop words and finally get the cleaned form\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    no_stop_words = [token.text for token in doc if not token.is_stop and not token.is_punct]\n",
    "    return \" \".join(no_stop_words)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca91a6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_word_2 = preprocess(text1)\n",
    "len(stop_word_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed667879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  good movie good movie\n"
     ]
    }
   ],
   "source": [
    "print(stop_word_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ff0e0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab['not'].is_stop = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adc29d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step2: send the two texts given above into the pre-process function and store the transformed texts\n",
    "stop_word_3 = []\n",
    "stop_word_3 = preprocess(text1)\n",
    "len(stop_word_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f394bb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  good movie good movie\n"
     ]
    }
   ],
   "source": [
    "#step3: finally print those 2 transformed texts\n",
    "print(stop_word_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RWnHxZy-Fv5S",
   "metadata": {
    "id": "RWnHxZy-Fv5S"
   },
   "source": [
    "**Exercise3:** \n",
    "\n",
    "- From a given text, output the **most frequently** used token after removing all the stop word tokens and punctuations in it. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "GfLMTZmBFlPI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GfLMTZmBFlPI",
    "outputId": "448095a9-954b-43e9-ad86-da7d48aed72c"
   },
   "outputs": [],
   "source": [
    "text = ''' The India men's national cricket team, also known as Team India or the Men in Blue, represents India in men's international cricket.\n",
    "It is governed by the Board of Control for Cricket in India (BCCI), and is a Full Member of the International Cricket Council (ICC) with Test,\n",
    "One Day International (ODI) and Twenty20 International (T20I) status. Cricket was introduced to India by British sailors in the 18th century, and the \n",
    "first cricket club was established in 1792. India's national cricket team played its first Test match on 25 June 1932 at Lord's, becoming the sixth team to be\n",
    "granted test cricket status.\n",
    "'''\n",
    "\n",
    "\n",
    "#step1: Create the object 'doc' for the given text using nlp()\n",
    "doc = nlp(text)\n",
    "\n",
    "#step2: remove all the stop words and punctuations and store all the remaining tokens in a new list\n",
    "rem_text = []\n",
    "for token in doc:\n",
    "      if token.is_stop or token.is_punct:    #check whether a given token is stop word or punctuations\n",
    "        continue\n",
    "      rem_text.append(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "606a55dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'India': 6, 'men': 2, 'national': 2, 'cricket': 5, 'team': 3, 'known': 1, 'Team': 1, 'Men': 1, 'Blue': 1, 'represents': 1, 'international': 1, 'governed': 1, 'Board': 1, 'Control': 1, 'Cricket': 3, 'BCCI': 1, 'Member': 1, 'International': 3, 'Council': 1, 'ICC': 1, 'Test': 2, 'Day': 1, 'ODI': 1, 'Twenty20': 1, 'T20I': 1, 'status': 2, 'introduced': 1, 'British': 1, 'sailors': 1, '18th': 1, 'century': 1, 'club': 1, 'established': 1, '1792': 1, 'played': 1, 'match': 1, '25': 1, 'June': 1, '1932': 1, 'Lord': 1, 'sixth': 1, 'granted': 1, 'test': 1}\n"
     ]
    }
   ],
   "source": [
    "#step3: create a new dictionary and get the frequency of words by iterating through the list which contains stored tokens \n",
    "\n",
    "frequency_tokens={}\n",
    "for token in rem_text:\n",
    "    if token != '\\n' and token != ' ':\n",
    "        if token not in frequency_tokens: \n",
    "             frequency_tokens[token] = 1\n",
    "        else:\n",
    "              frequency_tokens[token] += 1    \n",
    "print(frequency_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da4184ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'India'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step4: get the maximum frequency word\n",
    "max_freq_word = max(frequency_tokens.keys(), key=(lambda key: frequency_tokens[key]))\n",
    "max_freq_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b22d5afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum frequency word: India\n"
     ]
    }
   ],
   "source": [
    "#step5: finally print the result\n",
    "print(f\"Maximum frequency word: {max_freq_word}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5312ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "stop_words_exercise_solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
